{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RankGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMj/J9umY51SI5On/N4D8H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanSA05/ML/blob/main/RankGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-re2HeUxzdz",
        "outputId": "7bd9435e-dee4-45e6-f062-5cacf2d5d7e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/IntroToML/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u_ahb00ypfU",
        "outputId": "8c896610-e0a4-4553-f162-13d9724d6d15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y7-7ArdMy4qh",
        "outputId": "eb4ea08f-4a09-42e4-bda9-93e450fdb802"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/desire2020/RankGAN.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yio-8sBQy5SC",
        "outputId": "c5ec465e-fc9e-42d4-cecd-6b6b7a4d2ca7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RankGAN'...\n",
            "remote: Enumerating objects: 359, done.\u001b[K\n",
            "remote: Total 359 (delta 0), reused 0 (delta 0), pack-reused 359\u001b[K\n",
            "Receiving objects: 100% (359/359), 26.50 MiB | 9.96 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RankGAN/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUEaNOczy79W",
        "outputId": "ac45b165-918e-4f32-c2d2-0379eee478aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGN4SAhpzbPw",
        "outputId": "58dfbba2-6f79-45ef-e5f0-3ef608e2be7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sequence_gan.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s4DowNbzAkK",
        "outputId": "a16cec7c-336e-423d-a718-7d9350c59626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/generator.py:25: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/generator.py:27: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/generator.py:132: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/generator.py:34: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/generator.py:53: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/generator.py:54: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/generator.py:97: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/generator.py:212: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/discriminator.py:97: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/discriminator.py:111: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/discriminator.py:130: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/discriminator.py:44: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/discriminator.py:31: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/discriminator.py:161: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/11T4-AnRH3gQUdHY4MHkO3O5Gm6ZZa5rm/IntroToML/RankGAN/discriminator.py:204: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From sequence_gan.py:103: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From sequence_gan.py:105: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-12-13 22:04:45.340956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200205000 Hz\n",
            "2021-12-13 22:04:45.341291: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f3f72d4a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-13 22:04:45.341336: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-12-13 22:04:45.346258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-13 22:04:45.359210: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-12-13 22:04:45.359254: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (050b951d03a5): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From sequence_gan.py:106: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "Start pre-training...\n",
            "Pre-training generator epoch #0, loss=7.875005\n",
            "pre-train epoch  0 test_loss  10.194411\n",
            "Pre-training generator epoch #1, loss=7.714851\n",
            "Pre-training generator epoch #2, loss=7.582808\n",
            "Pre-training generator epoch #3, loss=7.428298\n",
            "Pre-training generator epoch #4, loss=7.280799\n",
            "Pre-training generator epoch #5, loss=7.150417\n",
            "pre-train epoch  5 test_loss  9.497405\n",
            "Pre-training generator epoch #6, loss=7.043664\n",
            "Pre-training generator epoch #7, loss=6.956404\n",
            "Pre-training generator epoch #8, loss=6.884642\n",
            "Pre-training generator epoch #9, loss=6.829195\n",
            "Pre-training generator epoch #10, loss=6.781245\n",
            "pre-train epoch  10 test_loss  9.2391405\n",
            "Pre-training generator epoch #11, loss=6.740940\n",
            "Pre-training generator epoch #12, loss=6.703770\n",
            "Pre-training generator epoch #13, loss=6.669995\n",
            "Pre-training generator epoch #14, loss=6.640520\n",
            "Pre-training generator epoch #15, loss=6.614143\n",
            "pre-train epoch  15 test_loss  9.251953\n",
            "Pre-training generator epoch #16, loss=6.586747\n",
            "Pre-training generator epoch #17, loss=6.564884\n",
            "Pre-training generator epoch #18, loss=6.542419\n",
            "Pre-training generator epoch #19, loss=6.519704\n",
            "Pre-training generator epoch #20, loss=6.499339\n",
            "pre-train epoch  20 test_loss  9.198747\n",
            "Pre-training generator epoch #21, loss=6.481605\n",
            "Pre-training generator epoch #22, loss=6.468838\n",
            "Pre-training generator epoch #23, loss=6.452670\n",
            "Pre-training generator epoch #24, loss=6.435346\n",
            "Pre-training generator epoch #25, loss=6.423808\n",
            "pre-train epoch  25 test_loss  9.165083\n",
            "Pre-training generator epoch #26, loss=6.411635\n",
            "Pre-training generator epoch #27, loss=6.404552\n",
            "Pre-training generator epoch #28, loss=6.389610\n",
            "Pre-training generator epoch #29, loss=6.381190\n",
            "Pre-training generator epoch #30, loss=6.370025\n",
            "pre-train epoch  30 test_loss  9.141619\n",
            "Pre-training generator epoch #31, loss=6.360969\n",
            "Pre-training generator epoch #32, loss=6.349292\n",
            "Pre-training generator epoch #33, loss=6.343668\n",
            "Pre-training generator epoch #34, loss=6.334267\n",
            "Pre-training generator epoch #35, loss=6.323346\n",
            "pre-train epoch  35 test_loss  9.109277\n",
            "Pre-training generator epoch #36, loss=6.314404\n",
            "Pre-training generator epoch #37, loss=6.303756\n",
            "Pre-training generator epoch #38, loss=6.299964\n",
            "Pre-training generator epoch #39, loss=6.294370\n",
            "Pre-training generator epoch #40, loss=6.291973\n",
            "pre-train epoch  40 test_loss  9.108457\n",
            "Pre-training generator epoch #41, loss=6.283637\n",
            "Pre-training generator epoch #42, loss=6.281661\n",
            "Pre-training generator epoch #43, loss=6.270511\n",
            "Pre-training generator epoch #44, loss=6.264333\n",
            "Pre-training generator epoch #45, loss=6.257322\n",
            "pre-train epoch  45 test_loss  9.095854\n",
            "Pre-training generator epoch #46, loss=6.256351\n",
            "Pre-training generator epoch #47, loss=6.251505\n",
            "Pre-training generator epoch #48, loss=6.249899\n",
            "Pre-training generator epoch #49, loss=6.255306\n",
            "Pre-training generator epoch #50, loss=6.240127\n",
            "pre-train epoch  50 test_loss  9.102766\n",
            "Pre-training generator epoch #51, loss=6.231494\n",
            "Pre-training generator epoch #52, loss=6.220002\n",
            "Pre-training generator epoch #53, loss=6.215358\n",
            "Pre-training generator epoch #54, loss=6.206352\n",
            "Pre-training generator epoch #55, loss=6.207159\n",
            "pre-train epoch  55 test_loss  9.095334\n",
            "Pre-training generator epoch #56, loss=6.210160\n",
            "Pre-training generator epoch #57, loss=6.205541\n",
            "Pre-training generator epoch #58, loss=6.202429\n",
            "Pre-training generator epoch #59, loss=6.195361\n",
            "Pre-training generator epoch #60, loss=6.192152\n",
            "pre-train epoch  60 test_loss  9.114794\n",
            "Pre-training generator epoch #61, loss=6.192200\n",
            "Pre-training generator epoch #62, loss=6.188890\n",
            "Pre-training generator epoch #63, loss=6.183974\n",
            "Pre-training generator epoch #64, loss=6.180506\n",
            "Pre-training generator epoch #65, loss=6.179318\n",
            "pre-train epoch  65 test_loss  9.094725\n",
            "Pre-training generator epoch #66, loss=6.186740\n",
            "Pre-training generator epoch #67, loss=6.179083\n",
            "Pre-training generator epoch #68, loss=6.174751\n",
            "Pre-training generator epoch #69, loss=6.165276\n",
            "Pre-training generator epoch #70, loss=6.163451\n",
            "pre-train epoch  70 test_loss  9.099834\n",
            "Pre-training generator epoch #71, loss=6.162900\n",
            "Pre-training generator epoch #72, loss=6.160615\n",
            "Pre-training generator epoch #73, loss=6.154337\n",
            "Pre-training generator epoch #74, loss=6.159939\n",
            "Pre-training generator epoch #75, loss=6.162670\n",
            "pre-train epoch  75 test_loss  9.086328\n",
            "Pre-training generator epoch #76, loss=6.156676\n",
            "Pre-training generator epoch #77, loss=6.153610\n",
            "Pre-training generator epoch #78, loss=6.148469\n",
            "Pre-training generator epoch #79, loss=6.152144\n",
            "Pre-training generator epoch #80, loss=6.145041\n",
            "pre-train epoch  80 test_loss  9.081693\n",
            "Pre-training generator epoch #81, loss=6.138240\n",
            "Pre-training generator epoch #82, loss=6.143363\n",
            "Pre-training generator epoch #83, loss=6.140602\n",
            "Pre-training generator epoch #84, loss=6.144492\n",
            "Pre-training generator epoch #85, loss=6.140341\n",
            "pre-train epoch  85 test_loss  9.091314\n",
            "Pre-training generator epoch #86, loss=6.130179\n",
            "Pre-training generator epoch #87, loss=6.124657\n",
            "Pre-training generator epoch #88, loss=6.131795\n",
            "Pre-training generator epoch #89, loss=6.139501\n",
            "Pre-training generator epoch #90, loss=6.142661\n",
            "pre-train epoch  90 test_loss  9.096342\n",
            "Pre-training generator epoch #91, loss=6.139457\n",
            "Pre-training generator epoch #92, loss=6.130970\n",
            "Pre-training generator epoch #93, loss=6.121603\n",
            "Pre-training generator epoch #94, loss=6.126139\n",
            "Pre-training generator epoch #95, loss=6.123689\n",
            "pre-train epoch  95 test_loss  9.102744\n",
            "Pre-training generator epoch #96, loss=6.116831\n",
            "Pre-training generator epoch #97, loss=6.118046\n",
            "Pre-training generator epoch #98, loss=6.114104\n",
            "Pre-training generator epoch #99, loss=6.120687\n",
            "Pre-training generator epoch #100, loss=6.121313\n",
            "pre-train epoch  100 test_loss  9.083937\n",
            "Pre-training generator epoch #101, loss=6.110758\n",
            "Pre-training generator epoch #102, loss=6.109480\n",
            "Pre-training generator epoch #103, loss=6.109262\n",
            "Pre-training generator epoch #104, loss=6.120378\n",
            "Pre-training generator epoch #105, loss=6.120997\n",
            "pre-train epoch  105 test_loss  9.093919\n",
            "Pre-training generator epoch #106, loss=6.118375\n",
            "Pre-training generator epoch #107, loss=6.112376\n",
            "Pre-training generator epoch #108, loss=6.107201\n",
            "Pre-training generator epoch #109, loss=6.096741\n",
            "Pre-training generator epoch #110, loss=6.093180\n",
            "pre-train epoch  110 test_loss  9.088777\n",
            "Pre-training generator epoch #111, loss=6.112070\n",
            "Pre-training generator epoch #112, loss=6.113051\n",
            "Pre-training generator epoch #113, loss=6.105614\n",
            "Pre-training generator epoch #114, loss=6.108059\n",
            "Pre-training generator epoch #115, loss=6.103535\n",
            "pre-train epoch  115 test_loss  9.0852375\n",
            "Pre-training generator epoch #116, loss=6.100590\n",
            "Pre-training generator epoch #117, loss=6.099153\n",
            "Pre-training generator epoch #118, loss=6.101250\n",
            "Pre-training generator epoch #119, loss=6.093396\n",
            "Start pre-training discriminator...\n",
            "Pre-training discriminator epoch #0, loss=-0.000750\n",
            "Pre-training discriminator epoch #1, loss=-0.000270\n",
            "Pre-training discriminator epoch #2, loss=0.003075\n",
            "Pre-training discriminator epoch #3, loss=0.001733\n",
            "Pre-training discriminator epoch #4, loss=-0.000581\n",
            "Pre-training discriminator epoch #5, loss=0.001856\n",
            "Pre-training discriminator epoch #6, loss=0.001522\n",
            "Pre-training discriminator epoch #7, loss=0.000167\n",
            "Pre-training discriminator epoch #8, loss=-0.000962\n",
            "Pre-training discriminator epoch #9, loss=-0.019447\n",
            "Pre-training discriminator epoch #10, loss=-0.026805\n",
            "Pre-training discriminator epoch #11, loss=-0.023477\n",
            "Pre-training discriminator epoch #12, loss=-0.051636\n",
            "Pre-training discriminator epoch #13, loss=-0.064086\n",
            "Pre-training discriminator epoch #14, loss=-0.077621\n",
            "Pre-training discriminator epoch #15, loss=-0.105229\n",
            "Pre-training discriminator epoch #16, loss=-0.093374\n",
            "Pre-training discriminator epoch #17, loss=-0.088330\n",
            "Pre-training discriminator epoch #18, loss=-0.099540\n",
            "Pre-training discriminator epoch #19, loss=-0.094373\n",
            "Pre-training discriminator epoch #20, loss=-0.124297\n",
            "Pre-training discriminator epoch #21, loss=-0.103302\n",
            "Pre-training discriminator epoch #22, loss=-0.123501\n",
            "Pre-training discriminator epoch #23, loss=-0.131473\n",
            "Pre-training discriminator epoch #24, loss=-0.124784\n",
            "Pre-training discriminator epoch #25, loss=-0.139268\n",
            "Pre-training discriminator epoch #26, loss=-0.158135\n",
            "Pre-training discriminator epoch #27, loss=-0.150047\n",
            "Pre-training discriminator epoch #28, loss=-0.155864\n",
            "Pre-training discriminator epoch #29, loss=-0.164169\n",
            "Pre-training discriminator epoch #30, loss=-0.151830\n",
            "Pre-training discriminator epoch #31, loss=-0.156526\n",
            "Pre-training discriminator epoch #32, loss=-0.172957\n",
            "Pre-training discriminator epoch #33, loss=-0.174612\n",
            "Pre-training discriminator epoch #34, loss=-0.123333\n",
            "Pre-training discriminator epoch #35, loss=-0.164181\n",
            "Pre-training discriminator epoch #36, loss=-0.164692\n",
            "Pre-training discriminator epoch #37, loss=-0.168206\n",
            "Pre-training discriminator epoch #38, loss=-0.159905\n",
            "Pre-training discriminator epoch #39, loss=-0.132495\n",
            "Pre-training discriminator epoch #40, loss=-0.161308\n",
            "Pre-training discriminator epoch #41, loss=-0.170426\n",
            "Pre-training discriminator epoch #42, loss=-0.177202\n",
            "Pre-training discriminator epoch #43, loss=-0.144590\n",
            "Pre-training discriminator epoch #44, loss=-0.183008\n",
            "Pre-training discriminator epoch #45, loss=-0.193406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nVxx8WWI0f2B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}